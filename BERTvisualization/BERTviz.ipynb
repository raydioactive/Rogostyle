{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa9e718a-5da1-4ef4-9496-892916fa158f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 13:03:18.334331: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2024-03-31 13:03:18.334393: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c9543b-6109-4ffc-a4a7-68ae7d6d297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = \"/slipstream_old/home/juliusherzog/latinbert/models/subword_tokenizer_latin/latin.subword.encoder\"\n",
    "                    \n",
    "# Load pre-trained model (weights)\n",
    "model = \"/slipstream_old/home/juliusherzog/latinbert/models/latin_bert/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41ba3dba-9c55-40b3-afc8-dee16b81d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, sys\n",
    "from cltk.tokenizers.lat.lat import LatinWordTokenizer as WordTokenizer\n",
    "from cltk.tokenizers.lat.lat import LatinPunktSentenceTokenizer as SentenceTokenizer\n",
    "from tensor2tensor.data_generators import text_encoder\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LatinBERT():\n",
    "\n",
    "\tdef __init__(self, tokenizerPath=None, bertPath=None):\n",
    "\t\tencoder = text_encoder.SubwordTextEncoder(tokenizerPath)\n",
    "\t\tself.wp_tokenizer = LatinTokenizer(encoder)\n",
    "\t\tself.model = BertLatin(bertPath=bertPath)\n",
    "\t\tself.model.to(device)\n",
    "\n",
    "\tdef get_batches(self, sentences, max_batch, tokenizer):\n",
    "\n",
    "\t\t\tmaxLen=0\n",
    "\t\t\tfor sentence in sentences:\n",
    "\t\t\t\tlength=0\n",
    "\t\t\t\tfor word in sentence:\n",
    "\t\t\t\t\ttoks=tokenizer.tokenize(word)\n",
    "\t\t\t\t\tlength+=len(toks)\n",
    "\n",
    "\t\t\t\tif length> maxLen:\n",
    "\t\t\t\t\tmaxLen=length\n",
    "\n",
    "\t\t\tall_data=[]\n",
    "\t\t\tall_masks=[]\n",
    "\t\t\tall_labels=[]\n",
    "\t\t\tall_transforms=[]\n",
    "\n",
    "\t\t\tfor sentence in sentences:\n",
    "\t\t\t\ttok_ids=[]\n",
    "\t\t\t\tinput_mask=[]\n",
    "\t\t\t\tlabels=[]\n",
    "\t\t\t\ttransform=[]\n",
    "\n",
    "\t\t\t\tall_toks=[]\n",
    "\t\t\t\tn=0\n",
    "\t\t\t\tfor idx, word in enumerate(sentence):\n",
    "\t\t\t\t\ttoks=tokenizer.tokenize(word)\n",
    "\t\t\t\t\tall_toks.append(toks)\n",
    "\t\t\t\t\tn+=len(toks)\n",
    "\n",
    "\t\t\t\tcur=0\n",
    "\t\t\t\tfor idx, word in enumerate(sentence):\n",
    "\t\t\t\t\ttoks=all_toks[idx]\n",
    "\t\t\t\t\tind=list(np.zeros(n))\n",
    "\t\t\t\t\tfor j in range(cur,cur+len(toks)):\n",
    "\t\t\t\t\t\tind[j]=1./len(toks)\n",
    "\t\t\t\t\tcur+=len(toks)\n",
    "\t\t\t\t\ttransform.append(ind)\n",
    "\n",
    "\t\t\t\t\ttok_ids.extend(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "\t\t\t\t\tinput_mask.extend(np.ones(len(toks)))\n",
    "\t\t\t\t\tlabels.append(1)\n",
    "\n",
    "\t\t\t\tall_data.append(tok_ids)\n",
    "\t\t\t\tall_masks.append(input_mask)\n",
    "\t\t\t\tall_labels.append(labels)\n",
    "\t\t\t\tall_transforms.append(transform)\n",
    "\n",
    "\t\t\tlengths = np.array([len(l) for l in all_data])\n",
    "\n",
    "\t\t\t# Note sequence must be ordered from shortest to longest so current_batch will work\n",
    "\t\t\tordering = np.argsort(lengths)\n",
    "\t\t\t\n",
    "\t\t\tordered_data = [None for i in range(len(all_data))]\n",
    "\t\t\tordered_masks = [None for i in range(len(all_data))]\n",
    "\t\t\tordered_labels = [None for i in range(len(all_data))]\n",
    "\t\t\tordered_transforms = [None for i in range(len(all_data))]\n",
    "\t\t\t\n",
    "\n",
    "\t\t\tfor i, ind in enumerate(ordering):\n",
    "\t\t\t\tordered_data[i] = all_data[ind]\n",
    "\t\t\t\tordered_masks[i] = all_masks[ind]\n",
    "\t\t\t\tordered_labels[i] = all_labels[ind]\n",
    "\t\t\t\tordered_transforms[i] = all_transforms[ind]\n",
    "\n",
    "\t\t\tbatched_data=[]\n",
    "\t\t\tbatched_mask=[]\n",
    "\t\t\tbatched_labels=[]\n",
    "\t\t\tbatched_transforms=[]\n",
    "\n",
    "\t\t\ti=0\n",
    "\t\t\tcurrent_batch=max_batch\n",
    "\n",
    "\t\t\twhile i < len(ordered_data):\n",
    "\n",
    "\t\t\t\tbatch_data=ordered_data[i:i+current_batch]\n",
    "\t\t\t\tbatch_mask=ordered_masks[i:i+current_batch]\n",
    "\t\t\t\tbatch_labels=ordered_labels[i:i+current_batch]\n",
    "\t\t\t\tbatch_transforms=ordered_transforms[i:i+current_batch]\n",
    "\n",
    "\t\t\t\tmax_len = max([len(sent) for sent in batch_data])\n",
    "\t\t\t\tmax_label = max([len(label) for label in batch_labels])\n",
    "\n",
    "\t\t\t\tfor j in range(len(batch_data)):\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tblen=len(batch_data[j])\n",
    "\t\t\t\t\tblab=len(batch_labels[j])\n",
    "\n",
    "\t\t\t\t\tfor k in range(blen, max_len):\n",
    "\t\t\t\t\t\tbatch_data[j].append(0)\n",
    "\t\t\t\t\t\tbatch_mask[j].append(0)\n",
    "\t\t\t\t\t\tfor z in range(len(batch_transforms[j])):\n",
    "\t\t\t\t\t\t\tbatch_transforms[j][z].append(0)\n",
    "\n",
    "\t\t\t\t\tfor k in range(blab, max_label):\n",
    "\t\t\t\t\t\tbatch_labels[j].append(-100)\n",
    "\n",
    "\t\t\t\t\tfor k in range(len(batch_transforms[j]), max_label):\n",
    "\t\t\t\t\t\tbatch_transforms[j].append(np.zeros(max_len))\n",
    "\n",
    "\t\t\t\tbatched_data.append(torch.LongTensor(batch_data))\n",
    "\t\t\t\tbatched_mask.append(torch.FloatTensor(batch_mask))\n",
    "\t\t\t\tbatched_labels.append(torch.LongTensor(batch_labels))\n",
    "\t\t\t\tbatched_transforms.append(torch.FloatTensor(batch_transforms))\n",
    "\n",
    "\t\t\t\tbsize=torch.FloatTensor(batch_transforms).shape\n",
    "\t\t\t\t\n",
    "\t\t\t\ti+=current_batch\n",
    "\n",
    "\t\t\t\t# adjust batch size; sentences are ordered from shortest to longest so decrease as they get longer\n",
    "\t\t\t\tif max_len > 100:\n",
    "\t\t\t\t\tcurrent_batch=12\n",
    "\t\t\t\tif max_len > 200:\n",
    "\t\t\t\t\tcurrent_batch=6\n",
    "\n",
    "\t\t\treturn batched_data, batched_mask, batched_transforms, ordering\n",
    "\n",
    "\n",
    "\tdef get_berts(self, raw_sents):\n",
    "\t\tsents = convert_to_toks(raw_sents)\n",
    "\t\tbatch_size = 32\n",
    "\t\tbatched_data, batched_mask, batched_transforms, ordering = self.get_batches(sents, batch_size, self.wp_tokenizer)\n",
    "\n",
    "\t\tordered_preds = []\n",
    "\t\t# Corrected handling of outputs and attentions\n",
    "\t\tfor b in range(len(batched_data)):\n",
    "\t\t\tsize = batched_transforms[b].shape\n",
    "\t\t\tb_size = size[0]\n",
    "\t\t\tout, attentions = self.model.forward(batched_data[b], attention_mask=batched_mask[b], transforms=batched_transforms[b])  # This now correctly captures the tuple's items\n",
    "\t\t\tout = out.detach()  # Detach only the output tensor\n",
    "\t\t\tout = out.cpu()\n",
    "\t\t\tfor row in range(b_size):\n",
    "\t\t\t\tordered_preds.append([np.array(r) for r in out[row]])\n",
    "\n",
    "\t\tpreds_in_order = [None for i in range(len(sents))]\n",
    "\n",
    "\t\tfor i, ind in enumerate(ordering):\n",
    "\t\t\tpreds_in_order[ind] = ordered_preds[i]\n",
    "\n",
    "\t\tbert_sents = []\n",
    "\n",
    "\t\tfor idx, sentence in enumerate(sents):\n",
    "\t\t\tbert_sent = []\n",
    "\n",
    "\t\t\tbert_sent.append((\"[CLS]\", preds_in_order[idx][0]))\n",
    "\n",
    "\t\t\tfor t_idx in range(1, len(sentence)-1):\n",
    "\t\t\t\ttoken = sentence[t_idx]\n",
    "\t\t\t\tpred = preds_in_order[idx][t_idx]\n",
    "\t\t\t\tbert_sent.append((token, pred))\n",
    "\n",
    "\t\t\tbert_sent.append((\"[SEP]\", preds_in_order[idx][len(sentence)-1]))\n",
    "\n",
    "\t\t\tbert_sents.append(bert_sent)\n",
    "\n",
    "\t\treturn bert_sents, attentions \n",
    "\n",
    "\n",
    "class LatinTokenizer():\n",
    "\tdef __init__(self, encoder):\n",
    "\t\tself.vocab={}\n",
    "\t\tself.reverseVocab={}\n",
    "\t\tself.encoder=encoder\n",
    "\n",
    "\t\tself.vocab[\"[PAD]\"]=0\n",
    "\t\tself.vocab[\"[UNK]\"]=1\n",
    "\t\tself.vocab[\"[CLS]\"]=2\n",
    "\t\tself.vocab[\"[SEP]\"]=3\n",
    "\t\tself.vocab[\"[MASK]\"]=4\n",
    "\n",
    "\t\tfor key in self.encoder._subtoken_string_to_id:\n",
    "\t\t\tself.vocab[key]=self.encoder._subtoken_string_to_id[key]+5\n",
    "\t\t\tself.reverseVocab[self.encoder._subtoken_string_to_id[key]+5]=key\n",
    "\n",
    "\n",
    "\tdef convert_tokens_to_ids(self, tokens):\n",
    "\t\twp_tokens=[]\n",
    "\t\tfor token in tokens:\n",
    "\t\t\tif token == \"[PAD]\":\n",
    "\t\t\t\twp_tokens.append(0)\n",
    "\t\t\telif token == \"[UNK]\":\n",
    "\t\t\t\twp_tokens.append(1)\n",
    "\t\t\telif token == \"[CLS]\":\n",
    "\t\t\t\twp_tokens.append(2)\n",
    "\t\t\telif token == \"[SEP]\":\n",
    "\t\t\t\twp_tokens.append(3)\n",
    "\t\t\telif token == \"[MASK]\":\n",
    "\t\t\t\twp_tokens.append(4)\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\twp_tokens.append(self.vocab[token])\n",
    "\n",
    "\t\treturn wp_tokens\n",
    "\n",
    "\tdef tokenize(self, text):\n",
    "\t\ttokens=text.split(\" \")\n",
    "\t\twp_tokens=[]\n",
    "\t\tfor token in tokens:\n",
    "\n",
    "\t\t\tif token in {\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"}:\n",
    "\t\t\t\twp_tokens.append(token)\n",
    "\t\t\telse:\n",
    "\n",
    "\t\t\t\twp_toks=self.encoder.encode(token)\n",
    "\n",
    "\t\t\t\tfor wp in wp_toks:\n",
    "\t\t\t\t\twp_tokens.append(self.reverseVocab[wp+5])\n",
    "\n",
    "\t\treturn wp_tokens\n",
    "\n",
    "def convert_to_toks(sents):\n",
    "\n",
    "\tsent_tokenizer = SentenceTokenizer()\n",
    "\tword_tokenizer = WordTokenizer()\n",
    "\n",
    "\tall_sents=[]\n",
    "\n",
    "\tfor data in sents:\n",
    "\t\ttext=data.lower()\n",
    "\n",
    "\t\tsents=sent_tokenizer.tokenize(text)\n",
    "\t\tfor sent in sents:\n",
    "\t\t\ttokens=word_tokenizer.tokenize(sent)\n",
    "\t\t\tfilt_toks=[]\n",
    "\t\t\tfilt_toks.append(\"[CLS]\")\n",
    "\t\t\tfor tok in tokens:\n",
    "\t\t\t\tif tok != \"\":\n",
    "\t\t\t\t\tfilt_toks.append(tok)\n",
    "\t\t\tfilt_toks.append(\"[SEP]\")\n",
    "\n",
    "\t\t\tall_sents.append(filt_toks)\n",
    "\n",
    "\treturn all_sents\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BertLatin(nn.Module):\n",
    "\n",
    "\tdef __init__(self, bertPath=None):\n",
    "\t\tsuper(BertLatin, self).__init__()\n",
    "\n",
    "\t\tself.bert = BertModel.from_pretrained(bertPath)\n",
    "\t\tself.bert.eval()\n",
    "\t\t\n",
    "\tdef forward(self, input_ids, token_type_ids=None, attention_mask=None, transforms=None):\n",
    "\n",
    "\t\tinput_ids = input_ids.to(device)\n",
    "\t\tattention_mask = attention_mask.to(device)\n",
    "\t\ttransforms = transforms.to(device)\n",
    "\t\t\n",
    "\t\toutputs = self.bert.forward(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
    "\t\t# 'outputs' from BERT is a transformers.modeling_outputs.BaseModelOutputWithCrossAttentions object\n",
    "\t\tsequence_outputs = outputs[0]\n",
    "\t\tpooled_outputs = outputs[1]\n",
    "\t\t\n",
    "\t\tall_layers=sequence_outputs\n",
    "\t\tout=torch.matmul(transforms,all_layers)\n",
    "\t\treturn out\n",
    "# python3 scripts/gen_berts.py --bertPath models/latin_bert/ --tokenizerPath models/subword_tokenizer_latin/latin.subword.encoder\n",
    "# if __name__ == \"__main__\":\n",
    "# \n",
    "# \tparser = argparse.ArgumentParser()\n",
    "# \tparser.add_argument('-b', '--bertPath', help='path to pre-trained BERT', required=True)\n",
    "# \tparser.add_argument('-t', '--tokenizerPath', help='path to Latin WordPiece tokenizer', required=True)\n",
    "# \t\n",
    "# \targs = vars(parser.parse_args())\n",
    "# \n",
    "# \tbertPath=args[\"bertPath\"]\n",
    "# \ttokenizerPath=args[\"tokenizerPath\"]\t\t\t\n",
    "# \n",
    "# \tbert=LatinBERT(tokenizerPath=tokenizerPath, bertPath=bertPath)\n",
    "# \n",
    "# \tsents=[\"arma virumque cano\", \"arma gravi numero violentaque bella parabam\"]\n",
    "# \t\n",
    "# \tbert_sents=bert.get_berts(sents)\n",
    "# \n",
    "# \tfor sent in bert_sents:\n",
    "# \t\tfor (token, bert) in sent:\n",
    "# \t\t\tprint(\"%s\\t%s\" % ( token, ' '.join([\"%.5f\" % x for x in bert])))\n",
    "# \t\tprint()\n",
    "\n",
    "\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86162bed-6c40-485c-84da-e24005edfc62",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m batched_data, batched_mask, _, _ \u001b[38;5;241m=\u001b[39m bert\u001b[38;5;241m.\u001b[39mget_batches(sents, \u001b[38;5;241m1\u001b[39m, bert\u001b[38;5;241m.\u001b[39mwp_tokenizer)  \u001b[38;5;66;03m# batch_size=1 for simplicity\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Extract output and attentions\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m out, attentions \u001b[38;5;241m=\u001b[39m \u001b[43mbert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Processing a single batch\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Ensure attentions is a list of tensors with shape [1, num_heads, seq_len, seq_len]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/latinbert/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[2], line 270\u001b[0m, in \u001b[0;36mBertLatin.forward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, transforms)\u001b[0m\n\u001b[1;32m    268\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    269\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m attention_mask\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 270\u001b[0m transforms \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m    272\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert\u001b[38;5;241m.\u001b[39mforward(input_ids, token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# 'outputs' from BERT is a transformers.modeling_outputs.BaseModelOutputWithCrossAttentions object\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# Assuming you have an instance `bert` of LatinBERT and a sentence prepared\n",
    "raw_sents = [\"arma virumque cano, Troiae qui primus ab oris\"]  # Example sentence\n",
    "sents = convert_to_toks(raw_sents)  # Convert sentences to token format\n",
    "\n",
    "# Assuming `get_batches` is appropriately defined to return tensors for input_ids and attention_mask\n",
    "batched_data, batched_mask, _, _ = bert.get_batches(sents, 1, bert.wp_tokenizer)  # batch_size=1 for simplicity\n",
    "\n",
    "# Extract output and attentions\n",
    "out, attentions = bert.model(batched_data[0], attention_mask=batched_mask[0])  # Processing a single batch\n",
    "\n",
    "# Ensure attentions is a list of tensors with shape [1, num_heads, seq_len, seq_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa31007-a41b-4775-bcf3-67d71aebb90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1185417/3480443343.py:124: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  batched_transforms.append(torch.FloatTensor(batch_transforms))\n"
     ]
    }
   ],
   "source": [
    "sents = [\"Si quid est in me ingeni, iudices, quod sentio quam sit exiguum, aut si qua exercitatio dicendi in qua me non infitior mediocriter esse versatum, aut si huiusce rei ratio aliqua ab optimarum artium studiis ac disciplina profecta, a qua ego nullum confiteor aetatis meae tempus abhorruisse, earum rerum omnium vel in primis hic A. Licinius fructum a me repetere prope suo iure debet.\",\n",
    "         \"Ac ne quis a nobis hoc ita dici forte miretur, quod alia quaedam in hoc facultas sit ingeni, neque haec dicendi ratio aut disciplina, ne nos quidem huic uni studio penitus umquam dediti fuimus.\"]\n",
    "bert = LatinBERT(tokenizerPath=\"/slipstream_old/home/juliusherzog/latinbert/models/subword_tokenizer_latin/latin.subword.encoder\",\n",
    "                 bertPath=\"/slipstream_old/home/juliusherzog/latinbert/models/latin_bert/\")\n",
    "bert_sents, attentions = bert.get_berts(sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f391bf61-9c53-43e1-a79c-42bb8854aa6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attention_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m bert\u001b[38;5;241m.\u001b[39mmodel(input_ids\u001b[38;5;241m=\u001b[39msents, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[43mattention_mask\u001b[49m)\n\u001b[1;32m      2\u001b[0m attentions \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Assuming attentions are the last item in the outputs tuple\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Now check the shape of the first layer's attentions for the first example in the batch\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'attention_mask' is not defined"
     ]
    }
   ],
   "source": [
    "outputs = bert.model(input_ids=sents, attention_mask=attention_mask)\n",
    "attentions = outputs[-1]  # Assuming attentions are the last item in the outputs tuple\n",
    "\n",
    "# Now check the shape of the first layer's attentions for the first example in the batch\n",
    "if attentions is not None and len(attentions) > 0:\n",
    "    print(attentions[0].shape)  # Expected shape: (batch_size, num_heads, sequence_length, sequence_length)\n",
    "else:\n",
    "    print(\"Attention weights are not available or empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9899a86c-142f-4b07-abae-659f3021d3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "# Example of checking the attention weights shape\n",
    "if attentions is not None and len(attentions) > 0:\n",
    "    print(attentions[0].shape)  # Print the shape of the first layer's attentions\n",
    "else:\n",
    "    print(\"Attention weights are not available or empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09fea39-d53a-4c83-98b9-70b4f985adfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n",
      "Special tokens have been added in the vocabulary, make sure the associated word emebedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "from bertviz import model_view\n",
    "\n",
    "model_path = \"/slipstream_old/home/juliusherzog/latinbert/models/latin_bert/\"\n",
    "tokenizer_path = \"/slipstream_old/home/juliusherzog/latinbert/models/subword_tokenizer_latin/latin.subword.encoder\"  \n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "# Load the model\n",
    "model = BertModel.from_pretrained(model_path, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647bc3e0-d51a-44a4-bcc8-62e887e90e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "text = \"Si quid est in me ingeni, iudices, quod sentio quam sit exiguum, aut si qua exercitatio dicendi in qua me non infitior mediocriter esse versatum, aut si huiusce rei ratio aliqua ab optimarum artium studiis ac disciplina profecta, a qua ego nullum confiteor aetatis meae tempus abhorruisse, earum rerum omnium vel in primis hic A. Licinius fructum a me repetere prope suo iure debet.\"\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b65b28b7-00db-4292-821d-4bc792fa4047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n",
      "Special tokens have been added in the vocabulary, make sure the associated word emebedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_path = \"/slipstream_old/home/juliusherzog/latinbert/models/subword_tokenizer_latin/latin.subword.encoder\"\n",
    "model_path = \"/slipstream_old/home/juliusherzog/latinbert/models/latin_bert/\"\n",
    "\n",
    "# Ensure that these paths are correct and point to the directory containing tokenizer and model files.\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc9b1f6f-2658-439b-bd3c-519d61c61557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /slipstream_old/home/juliusherzog/miniconda3/envs/latinbert/lib/python3.8/site-packages (0.1.99)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "410f86a6-bb83-4b64-8239-9a24c5fc22e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a custom model that isn't directly compatible with BertModel, adjustments might be necessary.\n",
    "model = BertModel.from_pretrained(model_path, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d8c48fb-81f1-4bc3-897f-ba0a44c9e4be",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Internal: src/sentencepiece_processor.cc(1101) [model_proto->ParseFromArray(serialized.data(), serialized.size())] ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentencepiece\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspm\u001b[39;00m\n\u001b[1;32m      3\u001b[0m sp \u001b[38;5;241m=\u001b[39m spm\u001b[38;5;241m.\u001b[39mSentencePieceProcessor()\n\u001b[0;32m----> 4\u001b[0m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/latinbert/lib/python3.8/site-packages/sentencepiece/__init__.py:905\u001b[0m, in \u001b[0;36mSentencePieceProcessor.Load\u001b[0;34m(self, model_file, model_proto)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_proto:\n\u001b[1;32m    904\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLoadFromSerializedProto(model_proto)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/latinbert/lib/python3.8/site-packages/sentencepiece/__init__.py:310\u001b[0m, in \u001b[0;36mSentencePieceProcessor.LoadFromFile\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadFromFile\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sentencepiece\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentencePieceProcessor_LoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Internal: src/sentencepiece_processor.cc(1101) [model_proto->ParseFromArray(serialized.data(), serialized.size())] "
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0ecb17b-2325-4d30-acd2-5e1c8e5144a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Your example text here.\n"
     ]
    }
   ],
   "source": [
    "text = \"Your example text here.\"\n",
    "print(type(text))  # Should be <class 'str'>\n",
    "print(text)        # Should print the actual text, ensuring it's not None or empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38a5f946-963d-462b-acc6-4db1069f3510",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/latinbert/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:555\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    553\u001b[0m     value \u001b[38;5;241m=\u001b[39m [value]\n\u001b[0;32m--> 555\u001b[0m tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# Removing this for now in favor of controling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of NoneType",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/latinbert/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1957\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   1938\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   1939\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1955\u001b[0m     )\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_pretokenized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/latinbert/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2027\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2019\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2020\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2025\u001b[0m )\n\u001b[0;32m-> 2027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_pretokenized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2045\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2046\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/latinbert/lib/python3.8/site-packages/transformers/tokenization_utils.py:451\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text)\n\u001b[1;32m    449\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text_pair) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_for_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfirst_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpair_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecond_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/latinbert/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2494\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.prepare_for_model\u001b[0;34m(self, ids, pair_ids, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   2491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_length:\n\u001b[1;32m   2492\u001b[0m     encoded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(encoded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 2494\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoded_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\n\u001b[1;32m   2496\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/latinbert/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:186\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    182\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m [encoding]\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encodings \u001b[38;5;241m=\u001b[39m encoding\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/latinbert/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:571\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    567\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m             )\n\u001b[0;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         )\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length."
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8ed0e6d-748c-42c2-9da3-5b4853a83f25",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minputs\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "print(inputs.keys())\n",
    "print(inputs['input_ids'].shape)\n",
    "print(inputs['attention_mask'].shape)\n",
    "outputs = model(**inputs)\n",
    "attention = outputs.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff77c8bb-bcc9-4fd9-b601-9b22b149afb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
